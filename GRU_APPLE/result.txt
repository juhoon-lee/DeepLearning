############ 파라미터 변경 예상 테스트 #####################
--------------------------------------

Layer - SingleGRU
모델 학습 시간: 17.5 sec
평가 손실: 0.00085
30일 예측 손실: 0.00798

layer = SingleGRU
hiddenState = 32
timeStep = 20
activation = tanh
epochs = 100
batchSize = 64
dataSize = 10
optimizer = adam
patience = 30

--------------------------------------

Layer - DoubleGRU
모델 학습 시간: 26.3 sec
평가 손실: 0.00110
30일 예측 손실: 0.00227

layer = DoubleGRU
hiddenState = 32
timeStep = 20
activation = tanh
epochs = 100
batchSize = 64
dataSize = 10
optimizer = adam
patience = 30

--------------------------------------

Layer - TripleGRU
모델 학습 시간: 46.2 sec
평가 손실: 0.001036
30일 예측 손실: 0.00325

layer = TripleGRU
hiddenState = 32
timeStep = 20
activation = tanh
epochs = 100
batchSize = 64
dataSize = 10
optimizer = adam
patience = 30

--------------------------------------

Activation - sigmoid
모델 학습 시간: 1.41e+03 sec
평가 손실: 0.00059
30일 예측 손실: 0.00568

layer = SingleGRU
hiddenState = 32
timeStep = 20
activation = sigmoid
epochs = 100
batchSize = 64
dataSize = 10
optimizer = adam
patience = 30

--------------------------------------

TimeStep - 10
모델 학습 시간: 13.5 sec
평가 손실: 0.00058
30일 예측 손실: 0.00469

layer = SingleGRU
hiddenState = 32
timeStep = 10
activation = tanh
epochs = 100
batchSize = 64
dataSize = 10
optimizer = adam
patience = 30

--------------------------------------

TimeStep - 40
모델 학습 시간: 27.3 sec
평가 손실: 0.000814
30일 예측 손실: 0.003901

layer = SingleGRU
hiddenState = 32
timeStep = 40
activation = tanh
epochs = 100
batchSize = 64
dataSize = 10
optimizer = adam
patience = 30

--------------------------------------

Epochs - 50
모델 학습 시간: 20.8 sec
평가 손실: 0.00081
30일 예측 손실: 0.00779

layer = SingleGRU
hiddenState = 32
timeStep = 20
activation = tanh
epochs = 50
batchSize = 64
dataSize = 10
optimizer = adam

--------------------------------------

Epochs - 100
모델 학습 시간: 42.9 sec
평가 손실: 0.00058
30일 예측 손실: 0.00852

layer = SingleGRU
hiddenState = 32
timeStep = 20
activation = tanh
epochs = 100
batchSize = 64
dataSize = 10
optimizer = adam
patience = 100

--------------------------------------
Epochs - 200
모델 학습 시간: 78.6 sec
평가 손실: 0.00037
30일 예측 손실: 0.01135

layer = SingleGRU
hiddenState = 32
timeStep = 20
activation = tanh
epochs = 200
batchSize = 64
dataSize = 10
optimizer = adam

--------------------------------------

BatchSize - 32
모델 학습 시간: 34.7 sec
평가 손실: 0.00050
30일 예측 손실: 0.0060

layer = SingleGRU
hiddenState = 32
timeStep = 20
activation = tanh
epochs = 200
batchSize = 32
dataSize = 10
optimizer = adam
patience = 30

--------------------------------------

BatchSize - 256
모델 학습 시간: 7.42 sec
평가 손실: 0.00073
30일 예측 손실: 0.00381

layer = SingleGRU
hiddenState = 32
timeStep = 20
activation = tanh
epochs = 200
batchSize = 256
dataSize = 10
optimizer = adam
patience = 30

--------------------------------------

DataSize - 5
모델 학습 시간: 17.3 sec
평가 손실: 0.00116
30일 예측 손실: 0.0086

layer = SingleGRU
hiddenState = 32
timeStep = 20
activation = tanh
epochs = 200
batchSize = 64
dataSize = 5
optimizer = adam
patience = 30

--------------------------------------

DataSize - 40
모델 학습 시간: 60.0 sec
평가 손실: 0.00050
30일 예측 손실: 0.00198

layer = SingleGRU
hiddenState = 32
timeStep = 20
activation = tanh
epochs = 200
batchSize = 64
dataSize = 40
optimizer = adam
patience = 30

--------------------------------------

Optimizer - SGD
모델 학습 시간: 28.8 sec
평가 손실: 0.00085
30일 예측 손실: 0.00120

layer = SingleGRU
hiddenState = 32
timeStep = 20
activation = tanh
epochs = 100
batchSize = 64
dataSize = 10
optimizer = sgd
patience = 30

--------------------------------------

Patience - 10
모델 학습 시간: 11.1 sec
평가 손실: 0.00084
30일 예측 손실: 0.00404

layer = SingleGRU
hiddenState = 32
timeStep = 20
activation = tanh
epochs = 100
batchSize = 64
dataSize = 10
optimizer = adam
patience = 10

--------------------------------------

Patience - 50
모델 학습 시간: 40.2 sec
평가 손실: 0.00048
30일 예측 손실: 0.01221

layer = SingleGRU
hiddenState = 32
timeStep = 20
activation = tanh
epochs = 100
batchSize = 64
dataSize = 10
optimizer = adam
patience = 50

--------------------------------------

HiddenState - 16
모델 학습 시간: 27.7 sec
평가 손실: 0.00074
30일 예측 손실: 0.00148

layer = SingleGRU
hiddenState = 16
timeStep = 20
activation = tanh
epochs = 100
batchSize = 64
dataSize = 10
optimizer = adam
patience = 30

--------------------------------------

HiddenState - 64
모델 학습 시간: 27.4 sec
평가 손실: 0.00053
30일 예측 손실: 0.00632

layer = SingleGRU
hiddenState = 64
timeStep = 20
activation = tanh
epochs = 100
batchSize = 64
dataSize = 10
optimizer = adam
patience = 30

--------------------------------------

###############최적의 파라미터 찾기##########################

--------------------------------------

Etc - Candidate Parameter 1
모델 학습 시간: 12.0 sec
평가 손실: 0.00097
30일 예측 손실: 0.00200

layer = SingleGRU
hiddenState = 16
timeStep = 40
activation = tanh
epochs = 100
batchSize = 256
dataSize = 40
optimizer = adam
patience = 10

--------------------------------------

Etc - Candidate Parameter 2
모델 학습 시간: 32.3 sec
평가 손실: 0.00093
30일 예측 손실: 0.00307

layer = SingleGRU
hiddenState = 16
timeStep = 40
activation = tanh
epochs = 100
batchSize = 256
dataSize = 40
optimizer = adam
patience = 30

--------------------------------------

Etc - Candidate Parameter 3
모델 학습 시간: 1.59e+02 sec
평가 손실: 0.00034
30일 예측 손실: 0.00059

layer = SingleGRU
hiddenState = 16
timeStep = 40
activation = tanh
epochs = 100
batchSize = 32
dataSize = 40
optimizer = adam
patience = 30

--------------------------------------

Etc - Candidate Parameter 4
모델 학습 시간: 6.37e+02 sec
평가 손실: 0.00027
30일 예측 손실: 0.00147

layer = TripleGRU
hiddenState = 64
timeStep = 40
activation = tanh
epochs = 200
batchSize = 32
dataSize = 40
optimizer = adam
patience = 50

--------------------------------------

ETC - Candidate Parameter 5
모델 학습 시간: 2e+02 sec
평가 손실: 0.00057
30일 예측 손실: 0.00972

layer = DoubleGRU
hiddenState = 16
timeStep = 20
activation = tanh
epochs = 100
batchSize = 32
dataSize = 40
optimizer = adam
patience = 30

--------------------------------------

ETC - Candidate Parameter 6
모델 학습 시간: 2.86e+02 sec
평가 손실: 0.000698
30일 예측 손실: 0.00137

layer = DoubleGRU
hiddenState = 16
timeStep = 40
activation = tanh
epochs = 100
batchSize = 32
dataSize = 40
optimizer = adam
patience = 30

--------------------------------------

ETC - Candidate Parameter 7
모델 학습 시간: 8.5e+02 sec
평가 손실: 0.000741216
30일 예측 손실: 0.00645531

layer = DoubleGRU
hiddenState = 16
timeStep = 40
activation = tanh
epochs = 100
batchSize = 32
dataSize = 40
optimizer = adam
patience = 100

--------------------------------------

Etc - OverFitting
모델 학습 시간: 2.19e+02 sec
평가 손실: 0.001162
30일 예측 손실: 0.003723

layer = TripleGRU
hiddenState = 64
timeStep = 40
activation = tanh
epochs = 200
batchSize = 32
dataSize = 5
optimizer = adam
patience = 100

--------------------------------------

